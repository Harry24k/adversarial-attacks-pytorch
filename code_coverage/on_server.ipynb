{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b108498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasse/Shashank_Projects/adversarial-attacks-pytorch/code_coverage/test_atks.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from test_atks import test_atks_on_cifar10, test_atks_on_cifar100, test_atks_on_imagenet1k\n",
    "from test_import import test_import_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d08de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "test_import_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd7a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea26465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************              IMAGENET-1k              *************************************\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004865884780883789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a8f42d2ba548f39e3cabe007d0fdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003263711929321289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_VANILA",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7164a46c5c194e0ab8926566517be559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_VANILA:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VANILA      : clean_acc=0.8342 robust_acc=0.8342 sec=9.6876\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0037183761596679688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_GN",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2df2e10ff947668c8fe4796e097c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_GN:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GN          : clean_acc=0.8342 robust_acc=0.8012 sec=9.7047\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0036880970001220703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_FGSM",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95d306330e647daab3fe34e1445188b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_FGSM:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM         occurs Error\n",
      "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.64 GiB total capacity; 22.92 GiB already allocated; 50.81 MiB free; 23.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003658294677734375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_BIM",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a2a07759604e2db8d263ebedccd2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_BIM:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIM          occurs Error\n",
      "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.64 GiB total capacity; 22.80 GiB already allocated; 50.81 MiB free; 23.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0040056705474853516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_RFGSM",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1d5a308f8a4c00a7af5eff75c5cbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_RFGSM:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFGSM        occurs Error\n",
      "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.64 GiB total capacity; 22.80 GiB already allocated; 50.81 MiB free; 23.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004238128662109375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "convnext_base_PGD",
       "rate": null,
       "total": 40,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0725a14c0dca4ddf9b178e3b1f7793eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convnext_base_PGD:   0%|          | 0/40 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD          occurs Error\n",
      "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.64 GiB total capacity; 22.80 GiB already allocated; 50.81 MiB free; 23.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7ffabdf5c860>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/prasse/miniconda3/envs/adv/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 529370, 529371, 529372, 529373, 529374, 529375, 529376, 529377, 529378, 529379, 529380, 529381, 529382, 529383, 529384, 529385, 529386, 529387, 529388, 529389, 529390, 529392) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_queue\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39m], timeout)\n\u001b[1;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 529389) is killed by signal: Terminated. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m atk_class \u001b[39min\u001b[39;00m [atk_class \u001b[39mfor\u001b[39;00m atk_class \u001b[39min\u001b[39;00m torchattacks\u001b[39m.\u001b[39m__all__ \u001b[39mif\u001b[39;00m atk_class \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m torchattacks\u001b[39m.\u001b[39m__wrapper__]:\n\u001b[0;32m----> 5\u001b[0m         test_atks_on_imagenet1k(atk_class\u001b[39m=\u001b[39matk_class,\n\u001b[1;32m      6\u001b[0m                                 device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                 model_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../demo/models/\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                 data_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/prasse/Shashank_Projects/adversarial-attacks-pytorch/data\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                 model\u001b[39m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Shashank_Projects/adversarial-attacks-pytorch/code_coverage/test_atks.py:195\u001b[0m, in \u001b[0;36mtest_atks_on_imagenet1k\u001b[0;34m(atk_class, device, n_examples, model_dir, data_dir, model)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     model \u001b[39m=\u001b[39m CACHE_img1k[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 195\u001b[0m dataset \u001b[39m=\u001b[39m load_imagenet(data_dir\u001b[39m=\u001b[39mdata_dir, shashank\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    197\u001b[0m test_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[1;32m    198\u001b[0m     dataset,\n\u001b[1;32m    199\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m     drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    206\u001b[0m \u001b[39m#lent=len(test_loader)\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m#for i, data in enumerate(test_loader):\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m#    import ipdb;ipdb.set_trace() \u001b[39;00m\n",
      "File \u001b[0;32m~/Shashank_Projects/adversarial-attacks-pytorch/robustbench/data.py:131\u001b[0m, in \u001b[0;36mload_imagenet\u001b[0;34m(n_examples, data_dir, transforms_test, shashank)\u001b[0m\n\u001b[1;32m    124\u001b[0m imagenet \u001b[39m=\u001b[39m CustomImageFolder(data_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/val\u001b[39m\u001b[39m'\u001b[39m, transforms_test)\n\u001b[1;32m    126\u001b[0m test_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mDataLoader(imagenet,\n\u001b[1;32m    127\u001b[0m                               batch_size\u001b[39m=\u001b[39mn_examples,\n\u001b[1;32m    128\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    129\u001b[0m                               num_workers\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m x_test, y_test, paths \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_loader))\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m shashank:\n\u001b[1;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m imagenet\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_get_data()\n\u001b[1;32m   1296\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/adv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 529370, 529371, 529372, 529373, 529374, 529375, 529376, 529377, 529378, 529379, 529380, 529381, 529382, 529383, 529384, 529385, 529386, 529387, 529388, 529389, 529390, 529392) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "print(\"*************************************              IMAGENET-1k              *************************************\")\n",
    "models = [\"convnext_tiny\", \"resnet50\", \"vit_small_patch16_224\", \"wide_resnet50_2\"]\n",
    "for model in models:\n",
    "    for atk_class in [atk_class for atk_class in torchattacks.__all__ if atk_class not in torchattacks.__wrapper__]:\n",
    "        test_atks_on_imagenet1k(atk_class=atk_class,\n",
    "                                device='cuda',\n",
    "                                model_dir='../demo/models/',\n",
    "                                data_dir='/home/prasse/Shashank_Projects/adversarial-attacks-pytorch/data',\n",
    "                                model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************************************              CIFAR-10              *************************************\")\n",
    "for atk_class in [atk_class for atk_class in torchattacks.__all__ if atk_class not in torchattacks.__wrapper__]:\n",
    "    test_atks_on_cifar10(atk_class=atk_class,\n",
    "                         device='cuda',\n",
    "                         model_dir='../demo/models/',\n",
    "                         data_dir='../demo/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a65de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************************************              CIFAR-100              *************************************\")\n",
    "for atk_class in [atk_class for atk_class in torchattacks.__all__ if atk_class not in torchattacks.__wrapper__]:\n",
    "    test_atks_on_cifar100(atk_class=atk_class,\n",
    "                         device='cuda',\n",
    "                         model_dir='../demo/models/',\n",
    "                         data_dir='../demo/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086977ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
